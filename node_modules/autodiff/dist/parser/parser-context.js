"use strict";
exports.__esModule = true;
var tokenizer_1 = require("./tokenizer");
var ParserContext = (function () {
    function ParserContext(_tokens) {
        this._tokens = _tokens;
    }
    ParserContext.prototype.hasMoreTokens = function () {
        return !this._tokens.isDone();
    };
    ParserContext.prototype.advanceToNextTokenOfType = function (tokenType) {
        while (this.peek().type !== tokenType && this.peek().type !== tokenizer_1.TokenType.EOF) {
            this.next();
        }
        return this.peek().type !== tokenizer_1.TokenType.EOF;
    };
    ParserContext.prototype.consumeIfType = function (tokenType) {
        if (this.peek().type === tokenType) {
            return this.next();
        }
        return null;
    };
    ParserContext.prototype.consumeIf = function (predicate) {
        var token = this.peek();
        if (predicate(token)) {
            return this._tokens.next();
        }
        return null;
    };
    ParserContext.prototype.peek = function () {
        var token = this._tokens.peek();
        return token ? token : { type: tokenizer_1.TokenType.EOF, value: null };
    };
    ParserContext.prototype.next = function () {
        var token = this.peek();
        this._tokens.next();
        return token;
    };
    return ParserContext;
}());
exports.ParserContext = ParserContext;
